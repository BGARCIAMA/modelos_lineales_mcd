---
title: "tarea_03_GLM_rdf"
authors: "Blanca E. García Manjarrez – 118886 Mariano Villafuerte Gonzalez – 156057
  Thomas M. Rudolf - 169293 Yuneri Pérez Arellano - 199813"
output:
  pdf_document: 
    latex_engine: xelatex
  html_document: default
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(gt)
library(ggplot2)
```

## Problema 1

Calcular el estimador de Monte Carlo de la integral

$\int_{0}^{pi/3} sin(t)\,dt$

y comparar el estimador con el valor exacto de la integral.

```{r}
## solución analitica
## integral de sin(t) es -cos(t)
sol_anlitica = -cos(pi/3) +cos(0)

## solución MCMC

num_samples = 10000
h <- function(t){sin(t)}
n_samples <- h(runif(num_samples, 0, pi/3))
result_n <- cumsum(n_samples)/(1:num_samples)
err_std <- sqrt(cumsum((n_samples-result_n)^2))/(1:num_samples)
plt_df_p1 <- data.frame(n=1:num_samples, 
                     result_n, 
                     err_std, 
                     upper = result_n + 2*err_std, 
                     lower = result_n - 2*err_std )
ggplot(plt_df_p1,  aes(x=n, y=result_n)) +
  geom_line() +
  geom_hline(yintercept = (-cos(pi/3)+cos(0))) +
  geom_line(aes(x=n, y=upper), color = "red") +
  geom_line(aes(x=n, y=lower), color = "red")
```

## Problema 2

Escribir una función para calcular el estimador de Monte Carlo de la
función de distribución Be (3, 3) y usar la función para estimar F(x)
para x = 0.1, . . . , 0.9. Comparar los estimados con los valores
obtenidos con la función pbeta de R.

```{r}
a = 3
b = 3
num_sample <- 10000
n = seq(0,1, length.out= num_sample)
plt_df_p2 <- data.frame(n, 
                        beta_dist = dbeta(n, a,b))

g2 <- ggplot(plt_df_p2, aes(x=n, y= beta_dist))+
  geom_line() +
  ylab("beta(3, 3)") 

## take samples
n_samples <- rbeta(num_sample, a,b)
## calculate I_hat 
I_hat <- sum(n_samples)/length(n_samples)
## vairanz asimtotic
var_I_hat <- sum((n_samples-I_hat)^2)/length(n_samples)
# estimator MC
estim_MC_p2 <- dnorm(seq(0,1, length.out=num_sample ),I_hat,  sqrt(var_I_hat) )

plt_df_p2 <- plt_df_p2 %>% mutate(estim_MC_p2)

g2 <- g2 + geom_line(aes(x=n, y = estim_MC_p2), color = "red")
g2


```

3.  Usar integración Monte Carlo para estimar:

    $\int_0^1 \frac{e^{-x}}{1+x^2}dx$

y calcular el tamaño de muestra necesario para obtener un error de
estimación máximo de ±0.001

```{r}
N <- 1000
err_estim_max <- 0.001
h <- function(x){
  return(exp(-x)/(1+x^2))
}
x <- seq(0,1, length.out = N)
Int <- cumsum(h(x))/(1:N)
var_n <- sqrt((x-Int)^2)/(1:N)

# find the first value that fulfils err_estim_max
min_num_samples <- which(var_n < err_estim_max)[1]
plt_df_p3 <- data.frame(x = x, 
                        y = Int, 
                        fcn=h(x))
ggplot(plt_df_p3, aes(x=x, y=y)) +
  geom_line() +
  geom_line(aes(x=x, y=fcn), color="red")

print("tamaño de muestra necesario:")
print(min_num_samples)


  
```

4.  Sea $\hat{\theta}_{IS}$ el estimador de importancia de
    $\theta = \int g(x) dx$, donde la función de importancia $f$ es una
    densidad. Probar que si $g(x)/f(x)$ es acotada, entonces la varianza
    del estimador de muestreo por importancia $\hat{\sigma}_IS$ es
    finita.

5.  Encontrar dos funciones de importancia f1 y f2 que tengan soporte en
    (1, ∞) y estén ‘cerca’ de:
    $g(x) = \frac{x^2}{\sqrt{2\pi}} e^{\frac{-x^2}{2}}$, x \> 1

    ¿Cuál de las dos funciones de importancia debe producir la varianza
    más pequeña para estimar la integral siguiente por muestreo de
    importancia?

    $\int_1^\inf{\frac{x^2}{\sqrt{2\pi}} e^{\frac{-x^2}{2}}}$

```{r}
## plot g(x)
N <- 10000
x <- seq(1, 5, length.out = N)
g <- function(x){
  g <- x^2/sqrt(2*pi) * exp(-x^2 / 2)
  return(g)
}
y <- g(x)
plt_df_p5 <- data.frame(x = x,
                        y = y)

## gamma distribution has a similar form as g(x)
dist_IS1 <- dgamma(x, 5,3)#/1.7
dist_IS2 <- dnorm(x, 1.4,0.8)#/1.6
plt_df_p5 <- plt_df_p5 %>% mutate(f1 = dist_IS1,
                                  f2 = dist_IS2) 
g5 <- ggplot(plt_df_p5, aes(x=x, y=y))+
  geom_line()


g5 <- g5 + geom_line(aes(x=x, y=f1), color="red") +
  geom_line(aes(x=x, y=f2), color="green") +
    labs(title = "Function and IS Function to ensure that:\n 1. it is easy to simulate\n 2. the funcions are similar to f(theta) \n 3. has heavier tail than f(theta)\n the red one is a gamma distribution and the green one a normal distribution",
       x = "samples",
       y = "Densidad funcitons", 
       colours)
g5
  
```


```{r}
## sample of f1
n = 1000
sample_f1 <- rgamma(n,5,3)#/1.7
sample_f2 <- rnorm(n, 1.4,0.8)#/1.6

## Calculating I_hat_MI1
I_hat_MI1 <- 1/n* sum(g(sample_f1)/(pgamma(sample_f1, 5,3))) #/1.7
## Calculating I_hat_MI2
I_hat_MI2 <- 1/n* sum(g(sample_f2)/(pnorm(sample_f2, 1.4,0.8)))#/1.6
```

