---
title: "tarea_03_GLM_rdf"
authors: "Blanca E. García Manjarrez – 118886 Mariano Villafuerte Gonzalez – 156057
  Thomas M. Rudolf - 169293 Yuneri Pérez Arellano - 199813"
output:
  pdf_document: 
    latex_engine: xelatex
  html_document: default
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(gt)
library(ggplot2)
```

## Problema 1

Calcular el estimador de Monte Carlo de la integral

$\int_{0}^{pi/3} sin(t)\,dt$

y comparar el estimador con el valor exacto de la integral.

```{r}
## solución analitica
## integral de sin(t) es -cos(t)
sol_anlitica = -cos(pi/3) +cos(0)

## solución MCMC

num_samples = 100000
h <- function(t){sin(t)}
n_samples <- h(runif(num_samples, 0, pi/3))
result_n <- cumsum(n_samples)/(1:num_samples)
err_std <- sqrt(cumsum((n_samples-result_n)^2))/(1:num_samples)
plt_df_p1 <- data.frame(n=1:num_samples, 
                     result_n, 
                     err_std, 
                     upper = result_n + 2*err_std, 
                     lower = result_n - 2*err_std )
ggplot(plt_df_p1,  aes(x=n, y=result_n)) +
  geom_line() +
  geom_hline(yintercept = (-cos(pi/3)+cos(0))) +
  geom_line(aes(x=n, y=upper), color = "red") +
  geom_line(aes(x=n, y=lower), color = "red")
result_n[length(result_n)]

```

## Problema 2

Escribir una función para calcular el estimador de Monte Carlo de la
función de distribución Be (3, 3) y usar la función para estimar F(x)
para x = 0.1, . . . , 0.9. Comparar los estimados con los valores
obtenidos con la función pbeta de R.

```{r}
a = 3
b = 3
num_sample <- 10000
n = seq(0,1, length.out= num_sample)
plt_df_p2 <- data.frame(n, 
                        beta_dist = dbeta(n, a,b))

g2 <- ggplot(plt_df_p2, aes(x=n, y= beta_dist))+
  geom_line() +
  ylab("beta(3, 3)") 

## take samples
n_samples <- rbeta(num_sample, a,b)
## calculate I_hat 
I_hat <- sum(n_samples)/length(n_samples)
## vairanz asimtotic
var_I_hat <- sum((n_samples-I_hat)^2)/length(n_samples)
# estimator MC
estim_MC_p2 <- dnorm(seq(0,1, length.out=num_sample ),I_hat,  sqrt(var_I_hat) )

plt_df_p2 <- plt_df_p2 %>% mutate(estim_MC_p2)

g2 <- g2 + geom_line(aes(x=n, y = estim_MC_p2), color = "red")
g2


```

3.  Usar integración Monte Carlo para estimar:

    $\int_0^1 \frac{e^{-x}}{1+x^2}dx$

y calcular el tamaño de muestra necesario para obtener un error de
estimación máximo de ±0.001

```{r}
N <- 1000
err_estim_max <- 0.001
h <- function(x){
  return(exp(-x)/(1+x^2))
}
x <- seq(0,1, length.out = N)
Int <- cumsum(h(x))/(1:N)
var_n <- sqrt((x-Int)^2)/(1:N)

# find the first value that fulfils err_estim_max
min_num_samples <- which(var_n < err_estim_max)[1]
plt_df_p3 <- data.frame(x = x, 
                        y = Int, 
                        fcn=h(x))
ggplot(plt_df_p3, aes(x=x, y=y)) +
  geom_line() +
  geom_line(aes(x=x, y=fcn), color="red")

print("tamaño de muestra necesario:")
print(min_num_samples)


  
```

4.  Sea $\hat{\theta}_{IS}$ el estimador de importancia de
    $\theta = \int g(x) dx$, donde la función de importancia $f$ es una
    densidad. Probar que si $g(x)/f(x)$ es acotada, entonces la varianza
    del estimador de muestreo por importancia $\hat{\sigma}_IS$ es
    finita.

5.  Encontrar dos funciones de importancia f1 y f2 que tengan soporte en
    (1, ∞) y estén ‘cerca’ de:
    $g(x) = \frac{x^2}{\sqrt{2\pi}} e^{\frac{-x^2}{2}}$, x \> 1

    ¿Cuál de las dos funciones de importancia debe producir la varianza
    más pequeña para estimar la integral siguiente por muestreo de
    importancia?

    $\int_1^\inf{\frac{x^2}{\sqrt{2\pi}} e^{\frac{-x^2}{2}}}$

```{r}
## plot g(x)
N <- 10000
x <- seq(1, 5, length.out = N)
g <- function(x){
  g <- x^2/sqrt(2*pi) * exp(-x^2 / 2)
  return(g)
}
y <- g(x)
plt_df_p5 <- data.frame(x = x,
                        y = y)

## gamma distribution has a similar form as g(x)
dist_IS1 <- dgamma(x, 5,3)#/1.7
dist_IS2 <- dnorm(x, 1.4,0.8)#/1.6
plt_df_p5 <- plt_df_p5 %>% mutate(f1 = dist_IS1,
                                  f2 = dist_IS2) 
g5 <- ggplot(plt_df_p5, aes(x=x, y=y))+
  geom_line()


g5 <- g5 + geom_line(aes(x=x, y=f1), color="red") +
  geom_line(aes(x=x, y=f2), color="green") +
    labs(title = "Function and IS Function to ensure that:\n 1. it is easy to simulate\n 2. the funcions are similar to f(theta) \n 3. has heavier tail than f(theta)\n the red one is a gamma distribution and the green one a normal distribution",
       x = "samples",
       y = "Densidad funcitons", 
       colours)
g5
  
```

```{r}
set.seed(123)
## sample of f1 and f2
n = 1000
sample_f1 <- rgamma(n,5,3)#/1.7
sample_f2 <- rnorm(n, 1.4,0.8)#/1.6

## Calculating I_hat_MI1
I_hat_MI1 <- 1/n* sum(g(sample_f1)/(pgamma(sample_f1, 5,3))) #/1.7
##calculating the varianz of f1
var_f1 <- 1/n^2 * sum(((g(sample_f1)/(pgamma(sample_f1, 5,3)))- I_hat_MI1)^2)
## Calculating I_hat_MI2
I_hat_MI2 <- 1/n* sum(g(sample_f2)/(pnorm(sample_f2, 1.4,0.8)))#/1.6
##calculating the varianz of f2
var_f2 <- 1/n^2 * sum(((g(sample_f2)/(pnorm(sample_f1, 1.4,0.8)))- I_hat_MI2)^2)
## result
result_df_p5 <- data.frame(I_hat = c(I_hat_MI1,I_hat_MI2),
                           var_I_hat = c(var_f1, var_f2))
result_df_p5 %>% gt()
```

6.  Usar el algoritmo de Metropolis-Hastings para generar variadas
    aleatorias de una densidad Cauchy estándar. Descartar las primeras
    1000 observaciones de la cadena, y comparar los deciles de las
    observaciones generadas con los deciles de la distribución Cauchy
    estándar. Recordar que una densidad Cauchy(θ,η) tiene densidad dada
    por la siguiente función:

    $f(x) = \frac {1}{\theta \pi (1 + [\frac{x-\nu}{\theta}]^2)}, x ∈ R, θ > 0$

    La densidad Cauchy estándar tiene θ = 1, η = 0, y corresponden a la
    densidad t con un grado de libertad.
    
    some info: https://www.youtube.com/watch?v=0lpT-yveuIA, https://www.youtube.com/watch?v=yCv2N7wGDCw, https://www.youtube.com/watch?v=yApmR-c_hKU&t=0s, https://www.youtube.com/watch?v=prZMpThbU3E&t=0s
```{r}
set.seed(123)
fcn_P6 <- function(x, nu, theta) {
  den_f = theta*pi*(1+((x-nu)/theta)^2) 
  f = 1/den_f
  return(f)
}
N = 10000
# 
theta <- 1
nu <- 0
x <- seq(-10, 10, length.out = N)
pdf_Cauchy_estandard <- fcn_P6(x, 0, 1)
plt_df_p6 <- data.frame(x,
                       y = fcn_P6(x, nu, theta))
ggplot(plt_df_p6, aes(x=x, y=y))+
  geom_line()


```
Since Cauchy distribution is symmetric, one can choose a normal distribution as $s(\theta)$ and $\frac{Q(\theta|\theta^*)}{Q(\theta^*|\theta)}=1$

```{r}
# definition of normal distribution parameters: mu = 0, var = 1
mu_f <- 0
var_f <- 1
# start value:
x <- 1
#var <- 0.1
f_x <- fcn_P6(x, 0,1)#dnorm(x, mu_f, var_f)
x_vec <- c()

for(idx in 1:N){
  
  x_new <- rnorm(1, mu_f, var_f)
  f_x_new <- fcn_P6(x_new, 0,1)#dnorm(x_new, mu_f, var_f)
  acceptance <- min(1, f_x_new/f_x)
  compar_value = runif(1)
  x_vec <- append(x_vec, ifelse(compar_value<acceptance, x_new, x))
  f_x <- ifelse(compar_value<acceptance, f_x_new, f_x)
}

## reject the first 1001 samples
x_vec_result <- x_vec[1001:length(x_vec)]
x_vec_result_sorted <- sort(x_vec_result)
f_result_mcmc <- fcn_P6(x_vec_result_sorted, 0,1)#dnorm(x_vec_result_sorted, mu_f, var_f)

plt_df_p6_result <-  data.frame(x_mcmc = x_vec_result_sorted,
                                  f_result_mcmc = f_result_mcmc, 
                                fcn_P6_result = fcn_P6(x_vec_result_sorted, nu, theta))

ggplot(plt_df_p6_result) +
  geom_line(aes(x=x_mcmc, y = f_result_mcmc), colour = "red") +
  geom_line(aes(x=x_mcmc, y = fcn_P6_result), colour = "black")


# deciles
result_deciles <- data.frame(decile_perc =seq(0,1, by=0.1)*100,
                             dec_fcn_cauchy = quantile(plt_df_p6$y, probs=seq(0,1, by=0.1)), 
                             dec_fcn_mcmcm = quantile(plt_df_p6_result$f_result_mcmc, probs=seq(0,1, by=0.1)) )

result_deciles %>% gt()

  

```



7. Implementar un muestreador de Metropolis de caminata aleatoria para generar muestras de
una distribución estándar de Laplace:
$f(x) = \frac{1}{2}e^{-|x|}, x ∈ R$
Para el incremento, simula una normal estándar. Comparar las cadenas generadas cuando
la distribución propuesta tiene diferentes varianzas. Calcular las tasas de aceptación de cada
cadena.
```{r}
fcn_P7 <- function(x){ return(0.5*exp(-abs(x)))
}
N <- 100000
x = seq(-10,10, length.out=N)
plt_df_P7 <- data.frame(x = x, 
                        y = fcn_P7(x))
ggplot(plt_df_P7, aes(x=x, y=y))+
  geom_line()
```
```{r}

```

