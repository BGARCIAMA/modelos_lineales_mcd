---
title: "Modelo bayesiano jerárquico Poisson para los resultados de los partidos de la Premier League"
subtitle: "Proyecto Modelos Lineales Generalizados"
format: pdf
editor: visual
authors: 
  - "Blanca Garcia - 118886"
  - "Yuneri Perez - 199813"
  - "Thomas Rudolf - 169293"
  - "Mariano Villafuerte - 156057"
toc: true
toc-title: "Índice"
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "../Proyecto MLG")
```

```{r librerias, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(gt)
library(ggplot2)
library(rstan)
library(rstantools)
library(loo)
library(bayesplot)
library(tidyverse)
library(dplyr)
library(readr)
library(rjags)
library(coda)
library(mcmcplots)
library(stringr)
library(plyr)
library(xtable)
library(gridExtra)
library(MCMCvis)
library(patchwork)
theme_set(theme_light())
setwd("../Proyecto MLG")
source("plotPost.R")
set.seed(12345)
```

\newpage

# Abstract

El objetivo de este proyecto es la aplicación de un modelo bayesiano para la predicción de resultados de partidos de fútbol. Además, el modelo es capaz de calcular las probabilidades del posible resultado de goles en los partidos futuros y producir una clasificación confiable de los equipos. El modelo desarrollado es un modelo jerárquico que asume una distribución Poisson para los resultados de los goles.

\newpage

# Introducción

El fútbol es el deporte más grande y seguido del mundo y, según la FIFA, cuenta con unos 5,000 millones de seguidores en todo el planeta. En este proyecto se utilizará la inferencia bayesiana para predecir las victorias en los partidos de fútbol. Basado en los resultados y partidos de temporadas pasados, se quiere modelar / predecir los resultados de partidos.

\newpage

# Datos

Para este proyecto se utilizarán datos de la Premier League. Son los resultados de las últimas temporadas desde 2010-2011 hasta 2023-2024, obtenidos de la siguiente pagina:

[https://www.football-data.co.uk/englandm.php](#0){.uri}.

La siguiente tabla es un ejemplo de los datos de la Premier League.

```{r datos, warning=FALSE, echo=FALSE}
setwd('../')

E0 <- read_csv("data/E0.csv")
E0<- E0 |>  mutate(Season = "2023-2024")

E01 <- read_csv("data/E0 (1).csv", show_col_types = FALSE)
E01<- E01 |>  mutate(Season = "2022-2023")

E02 <- read_csv("data/E0 (2).csv", show_col_types = FALSE)
E02<- E02 |>  mutate(Season = "2021-2022")

E03 <- read_csv("data/E0 (3).csv", show_col_types = FALSE)
E03<- E03 |>  mutate(Season = "2020-2021")

E04 <- read_csv("data/E0 (4).csv", show_col_types = FALSE)
E04<- E04 |>  mutate(Season = "2019-2020")

E05 <- read_csv("data/E0 (5).csv", show_col_types = FALSE)
E05<- E05 |>  mutate(Season = "2018-2019")

E06 <- read_csv("data/E0 (6).csv", show_col_types = FALSE)
E06<- E06 |>  mutate(Season = "2017-2018")

E07 <- read_csv("data/E0 (7).csv", show_col_types = FALSE)
E07<- E07 |>  mutate(Season = "2016-2017")

E08 <- read_csv("data/E0 (8).csv", show_col_types = FALSE)
E08<- E08 |>  mutate(Season = "2015-2016")

E09 <- read_csv("data/E0 (9).csv", show_col_types = FALSE)
E09<- E09 |>  mutate(Season = "2014-2015")

E010 <- read_csv("data/E0 (10).csv", show_col_types = FALSE)
E010<- E010 |>  mutate(Season = "2013-2014")

E011 <- read_csv("data/E0 (11).csv", show_col_types = FALSE)
E011<- E011 |>  mutate(Season = "2012-2013")

E012 <- read_csv("data/E0 (12).csv", show_col_types = FALSE)
E012<- E012 |>  mutate(Season = "2011-2012")

E013 <- read_csv("data/E0 (13).csv", show_col_types = FALSE)
E013<- E013 |>  mutate(Season = "2010-2011")

# Unir todos los dataframes
dataPL_complete <- bind_rows(E0, E01, E02, E03, E04, E05, E06, E07, E08, E09, E010, E011, E012, E013)

quick_view <- dataPL_complete |>
  head() |>
  mutate(Date = as.Date(Date, format="%d/%m/%y"),
         Time = as.POSIXct(Time, format="%H:%M"))

# Verificar el resultado
quick_view |> 
  select(Div, Season,Date,Time,HomeTeam,AwayTeam,
         FTHG,FTAG,FTR,HTHG,HTAG,HTR,HS,AS,HST,AST,
         HF,AF,HC,AC,HY,AY,HR,AR) |>
  gt() |> 
  fmt_date(columns=c(Date), date_style = 7) |>
  fmt_time(columns=c(Time), time_style = 2)
```

La descripción de las variables de los datos de la Premier League son:

-   Div: Division
-   Season: Season
-   Date: Match Date (dd/mm/yyyy)
-   Time: Match Time
-   HomeTeam: Home Team
-   AwayTeam: Away Team
-   FTHG: Full Time Home Team Goals
-   FTAG: Full Time Away Team Goals
-   FTR: Full Time Result (H=Home Win, D=Draw, A=Away Win)
-   HTHG: Half Time Home Team Goals
-   HTAG: Half Time Away Team Goals
-   HTR: Half Time Result (H=Home Win, D=Draw, A=Away Win)
-   HS: Home Team Shots
-   AS: Away Team Shots
-   HST: Home Team Shots on Target
-   AST: Away Team Shots on Target
-   HF: Home Team Fouls Committed
-   AF: Away Team Fouls Committed
-   HC: Home Team Corners
-   AC: Away Team Corners
-   HY: Home Team Yellow Cards
-   AY: Away Team Yellow Cards
-   HR: Home Team Red Cards
-   AR: Away Team Red Cards

El objetivo del presente análisis, no es sólo modelar los resultados de los partidos en el conjunto de datos, sino también ser capaz de:

a)  Calcular las probabilidades del posible resultado de goles en los partidos futuros y

b)  Producir una clasificación confiable de los equipos.

Lo anterior, a partir del desarrollo de un **modelo jerárquico bayesiano**, donde el número de goles se supondrá que se distribuye de acuerdo con una distribución Poisson:

$$
\textrm{Goles}\sim \textrm{Poisson}(\lambda)
$$

A partir de este punto, se hicieron unas modificaciones al conjunto de datos original, de modo que se tuvieran nombres más intuitivos: HomeGoals en lugar de FTHG, AwayGoals en vez de FTAG y Result sustituye a FTR. De igual manera, se descompone la variable de la fecha del partido en sus distintos componentes: día, mes y año. Adicionalmente, se define la variable de MatchResult como:

$$
\textrm{MatchResult} = \left\{ \begin{array}{cl}
-1 & \text{Away win} \\
0 & \text{Draw} \\
1 & \text{Home win}
\end{array} \right.
$$

```{r preprocessing, echo=FALSE}
dataPL <- dataPL_complete |>
  select(Div, Season, Date, HomeTeam, AwayTeam, FTHG, FTAG, FTR) |>
  mutate(Date = as.Date(Date, format = "%d/%m/%y"),
         YearMatch = format(Date, "%y"),
         MonthMatch = format(Date, "%m"),
         DayMatch = format(Date, "%d")) |>
  dplyr::rename(HomeGoals = FTHG, 
                AwayGoals = FTAG, 
                Result = FTR)

# -1 Away win, 0 Draw, 1 Home win
dataPL$MatchResult <- sign(dataPL$HomeGoals - dataPL$AwayGoals) 

# Creating a data frame d with only the complete match results
d <- na.omit(dataPL)

teams <- unique(c(d$HomeTeam, d$AwayTeam))
seasons <- unique(d$Season)

# A list for JAGS with the data from d where the strings are coded as integers
data_list <- list(HomeGoals = d$HomeGoals, AwayGoals = d$AwayGoals, 
                  HomeTeam = as.numeric(factor(d$HomeTeam, levels=teams)),
                  AwayTeam = as.numeric(factor(d$AwayTeam, levels=teams)),
                  Season = as.numeric(factor(d$Season, levels=seasons)),
                  n_teams = length(teams), n_games = nrow(d), 
                  n_seasons = length(seasons))

# Convenience function to generate the type of column names Jags outputs.
col_name <- function(name, ...) {
  paste0(name, "[", paste(..., sep=",") , "]")
}
```

\newpage

# Métodos

Para el desarrollo del modelo, al ser jerárquico, se realizaron varias iteraciones, de modo que con cada iteración el modelo se va ajustando y busca ahondar en las problemáticas de este proyecto.

## Iteración 1

La primera iteración consiste en modelar la distribución del número de goles de cada equipo en un partido de fútbol. Para lograr esto, se supone que todos los partidos de fútbol tienen aproximadamente la misma duración, que ambos equipos tienen suficientes oportunidades de marcar un gol y que cada equipo tiene la misma probabilidad de marcar un gol en cada oportunidad.

Se puede asumir una distribución Poisson para el número de goles debido a la concentración en valores más bajos. Por lo general, lo más común es ver dos goles por partido (según nuestro conocimiento previo). Además, se puede suponer que el anotar un gol, no afecta la habilidad del equipo de meter o recibir otro gol (debatible por factores humanos).

Dadas estas suposiciones, la distribución del número de goles de cada equipo debería estar bien representada por una distribución `Poisson`.

La comparación entre la distribución real del número de goles marcados y una distribución `Poisson` con el mismo número medio de goles marcados corroborá esta definición:

```{r warning=FALSE, echo=FALSE}
# Combinar los goles en casa y fuera en un solo vector y crear un dataframe
goals_data <- data.frame(Goals = c(d$AwayGoals, d$HomeGoals))

# Histograma de los goles reales
p1 <- ggplot(goals_data, aes(x = Goals)) +
  geom_histogram(breaks = -1:9 + 0.5, fill = "purple", alpha = 0.5) +
  scale_x_continuous(limits = c(-0.5, 8)) +
  ggtitle("Dist. del número de goles marcados\npor un equipo en un partido") +
  theme_light()

# Calcular la media de goles
mean_goals <- mean(goals_data$Goals)

# Histograma basado en la distribución de Poisson
p2 <- ggplot(data.frame(Goals = rpois(9999, mean_goals)), aes(x = Goals)) +
  geom_histogram(breaks = -1:9 + 0.5, fill = "blue", alpha = 0.5) +
  scale_x_continuous(limits = c(-0.5, 8)) +
  ggtitle("Dist. aleatoria de Poisson con misma\nmedia que la distribución anterior") +
  theme_light()

p1+p2
```

\newpage

Es importante destacar que no todos los equipos son igual de buenos, por lo que para esto se supondrá que todos los equipos tienen una variable de habilidad latente y que la habilidad de un equipo menos la habilidad del equipo contrario define el resultado previsto de un partido. Como se supone que el número de goles tiene una distribución Poisson, es natural que las habilidades de los equipos estén en la escala logarítmica de la media de dicha distribución. La distribución del número de goles del equipo $i$ frente al equipo $j$ es la siguiente: $$Goals \sim Poisson(\lambda)$$ $$log(\lambda) = baseline + skill_i − skill_j$$donde la línea de base (baseline) es el promedio logarítmico del número de goles cuando ambos equipos son igual de buenos. El resultado de goles de un partido entre el equipo local $i$ y el equipo visitante $j$ se modela como: $$HomeGoals_{i,j} \sim Poison(\lambda_{home,i,j})$$ $$AwayGoals_{i,j} \sim Poison(\lambda_{away,i,j})$$ $$log(\lambda_{home,i,j}) = baseline + skill_i − skill_j$$ $$log(\lambda_{away,i,j}) = baseline + skill_j − skill_i$$Para contar con un modelo bayesiano agregaremos algunas distribuciones a priori sobre la línea de base (baseline) y la habilidad (skill) de todos los $n$ equipos: $$baseline \sim Normal(0, 4^2)$$ $$skill_{1...n} \sim Normal(\mu_{teams}, \sigma^2_{teams})$$ $$\mu_{teams} \sim Normal(0, 4^2)$$ $$\sigma_{teams} \sim U(0, 3)$$

Cabe destacar que con base al conocimiento que tenemos de fútbol se establecieron estas distribuciones a priori. Por ejemplo, el valor a priori de la línea de base (baseline) tiene una desviación estándar de 4, pero como está en la escala logarítmica del número medio de goles, corresponde a una desviación estándar de la media 0 que cubre el intervalo de \[0.02, 54.6\] goles. Convertir esto en un modelo `JAGS` requiere algunos ajustes menores.

El modelo tiene que pasar por todos los resultados de los partidos, lo que añade algunos ciclos `for`. Por último, tenemos que "anclar" la habilidad de un equipo a una constante, de lo contrario la habilidad media puede desviarse libremente. Estos ajustes dan como resultado el siguiente modelo:

```{r model1, echo=FALSE, tidy=FALSE}
model1 <- "model {
for(i in 1:n_games) {
  HomeGoals[i] ~ dpois(lambda_home[HomeTeam[i],AwayTeam[i]])
  AwayGoals[i] ~ dpois(lambda_away[HomeTeam[i],AwayTeam[i]])
}

for(home_i in 1:n_teams) {
  for(away_i in 1:n_teams) {
    lambda_home[home_i, away_i] <- exp(baseline + skill[home_i] - skill[away_i])
    lambda_away[home_i, away_i] <- exp(baseline + skill[away_i] - skill[home_i])
  }
}

skill[1] <- 0
for(j in 2:n_teams) {
  skill[j] ~ dnorm(group_skill, group_tau)
}  

group_skill ~ dnorm(0, 0.0625)
group_tau <- 1 / pow(group_sigma, 2)
group_sigma ~ dunif(0, 3)
baseline ~ dnorm(0, 0.0625)
}"
```

```{r fit_model1, warning=FALSE, message=FALSE, echo=FALSE, results='hide', cache=TRUE}
# Compiling model 1
model1_fit <- jags.model(textConnection(model1), data=data_list, n.chains=4, n.adapt=5000)
# Burning some samples on the altar of the MCMC god
update(model1_fit, 5000)
# Generating MCMC samples
samples1 <- coda.samples(model1_fit, variable.names=c("baseline", "skill", "group_skill", "group_sigma"), n.iter=10000, thin=2)
# Merging the three MCMC chains into one matrix
matrix_samples1 <- as.matrix(samples1)
```

```{r tbl_model1, echo=FALSE}
sum_samples1 <- summary(samples1)
summary_df <- as.data.frame(sum_samples1$statistics)
summary_df$parameter <- rownames(summary_df)

quantiles_df <- as.data.frame(sum_samples1$quantiles)
quantiles_df$parameter <- rownames(quantiles_df)
summary_combined_df <- left_join(summary_df, quantiles_df, by = "parameter")

tbl_model1 <- summary_combined_df |>
  select(parameter, Mean, SD = SD, "2.5%", "97.5%")

tbl_model1 |>
  gt() |>
  fmt_number(columns = c("Mean", "SD", "2.5%", "97.5%"), decimals = 3)
```

Utilizando las muestras MCMC generadas, ahora se puede observar los valores de habilidad creíbles de cualquier equipo.

Veamos la traza y la distribución de los parámetros de habilidad (skill) del `Chelsea` y el `Tottenham`:

```{r graphs_model1_Chelsea, warning=FALSE, echo=FALSE}
mean_ch <- tbl_model1$Mean[12]

mcmc_trace_ch <- MCMCtrace(samples1, params = "skill[9]",
                           ISB = FALSE, 
                           exact = TRUE, 
                           pdf = FALSE,
                           ind = TRUE,
                           main_tr = 'Traza de Skill de Chelsea',
                           main_den = 'Distribución de Skill de Chelsea',
                           gvals = mean_ch)
```

```{r graphs_model1_Tottenham, warning=FALSE, echo=FALSE}
mean_ch <- tbl_model1$Mean[18]

mcmc_trace_ch <- MCMCtrace(samples1, params = "skill[15]",
                           ISB = FALSE, 
                           exact = TRUE, 
                           pdf = FALSE,
                           ind = TRUE,
                           main_tr = 'Traza Skill de Tottenham',
                           main_den = 'Distribución Skill de Tottenham',
                           gvals = mean_ch)
```

\newpage

Parece que el `Chelsea` y el `Tottenham` tienen una habilidad similar, siendo el `Chelsea` ligeramente mejor. Utilizando las muestras MCMC no sólo es posible observar la distribución de los valores de los parámetros, sino que también es sencillo simular partidos entre equipos y observar una distribución creíble del número de goles marcados y la probabilidad de victoria del equipo local, victoria del equipo visitante o empate. Las funciones del Anexo 1 simulan partidos con un equipo como local y otro como visitante y representan el resultado previsto junto con los resultados reales de cualquier partido del conjunto de datos de la `Premier League`.

```{r functions_match_result, echo=FALSE}
# Plots histograms over home_goals, away_goals, the difference in goals and a barplot over the credible match results.
plot_goals <- function(home_goals, away_goals) {
  n_matches <- length(home_goals)
  goal_diff <- home_goals - away_goals
  match_result <- ifelse(goal_diff < 0, "away_win", ifelse(goal_diff > 0, "home_win", "equal"))
  hist(home_goals, xlim=c(-0.5, 10), breaks=(0:100) - 0.5)
  hist(away_goals, xlim=c(-0.5, 10), breaks=(0:100) - 0.5)
  hist(goal_diff, xlim=c(-6, 6), breaks=(-100:100) - 0.5 )
  barplot(table(match_result) / n_matches , ylim=c(0, 1))
}

# Simulates game goals scores using the MCMC samples from the model1.
plot_pred_comp1 <- function(home_team, away_team, ms) {
  old_par <- par(mfrow = c(2, 4))
  baseline <- ms[, "baseline"]
  home_skill <- ms[, col_name("skill", which(teams == home_team))]
  away_skill <- ms[, col_name("skill", which(teams == away_team))]
  home_goals <- rpois(nrow(ms),  exp(baseline +  home_skill - away_skill))
  away_goals <- rpois(nrow(ms),  exp(baseline +  away_skill - home_skill))
  plot_goals(home_goals, away_goals)
  home_goals <- d$HomeGoals[ d$HomeTeam == home_team & d$AwayTeam == away_team]
  away_goals <- d$AwayGoals[ d$HomeTeam == home_team & d$AwayTeam == away_team]
  plot_goals(home_goals, away_goals)
  par(old_par)
}
```

```{r function_plot_MatchResult, echo=FALSE}
plot_goals <- function(home_goals, away_goals, title_suffix) {
  n_matches <- length(home_goals)
  goal_diff <- home_goals - away_goals
  match_result <- ifelse(goal_diff < 0, "away_win", ifelse(goal_diff > 0, "home_win", "equal"))
  
  data <- data.frame(
    home_goals = home_goals,
    away_goals = away_goals,
    goal_diff = goal_diff,
    match_result = factor(match_result, levels = c("home_win", "equal", "away_win"))
  )
  
  p1 <- ggplot(data, aes(x = home_goals)) +
    geom_histogram(binwidth = 1, color = "black", fill = "steelblue3") +
    xlim(-0.5, 10) +
    ggtitle(paste("Home Goals", title_suffix)) +
    theme(plot.title = element_text(size = 8))
  
  p2 <- ggplot(data, aes(x = away_goals)) +
    geom_histogram(binwidth = 1, color = "black", fill = "orchid3") +
    xlim(-0.5, 10) +
    ggtitle(paste("Away Goals", title_suffix)) +
    theme(plot.title = element_text(size = 8))
  
  p3 <- ggplot(data, aes(x = goal_diff)) +
    geom_histogram(binwidth = 1, color = "black", fill = "turquoise3") +
    xlim(-6, 6) +
    ggtitle(paste("Goal Difference", title_suffix)) +
    theme(plot.title = element_text(size = 8))
  
  p4 <- ggplot(data, aes(x = match_result)) +
    geom_bar(aes(y = ..prop.., group = 1), color = "black", fill = "slateblue2") +
    ylim(0, 1) +
    ggtitle(paste("Match Results", title_suffix)) +
    theme(plot.title = element_text(size = 8))
  
  list(p1, p2, p3, p4)
}

plot_pred_comp1 <- function(home_team, away_team, ms) {
  baseline <- ms[, "baseline"]
  home_skill <- ms[, col_name("skill", which(teams == home_team))]
  away_skill <- ms[, col_name("skill", which(teams == away_team))]
  
  home_goals_sim <- rpois(nrow(ms), exp(baseline + home_skill - away_skill))
  away_goals_sim <- rpois(nrow(ms), exp(baseline + away_skill - home_skill))
  
  sim_plots <- plot_goals(home_goals_sim, away_goals_sim, "(Simulated)")
  
  home_goals_real <- d$HomeGoals[d$HomeTeam == home_team & d$AwayTeam == away_team]
  away_goals_real <- d$AwayGoals[d$HomeTeam == home_team & d$AwayTeam == away_team]
  
  real_plots <- plot_goals(home_goals_real, away_goals_real, "(Actual)")
  
  grid.arrange(
    sim_plots[[1]], sim_plots[[2]], sim_plots[[3]], sim_plots[[4]],
    real_plots[[1]], real_plots[[2]], real_plots[[3]], real_plots[[4]],
    nrow = 2, ncol = 4
  )
}
```

De modo que se puede simular un partido del `Chelsea` (HomeTeam) contra el `Tottenham` (AwayTeam). El siguiente gráfico muestra la simulación en la primera fila y los datos históricos en la segunda.

```{r match_result_ChelseavsTottenham, echo=FALSE, warning=FALSE}
plot_pred_comp1("Chelsea", "Tottenham", matrix_samples1)
```

Los datos simulados se ajustan razonablemente bien a los datos históricos y tanto los datos históricos como la simulación muestran que el `Chelsea` ganaría con una probabilidad ligeramente superior a la del `Tottenham`. Ahora intercambiemos los lugares y dejemos que el `Tottenham` sea el equipo local (HomeTeam) y el `Chelsea` sea el equipo visitante (AwayTeam).

```{r match_result_TottenhamvsChelsea, echo=FALSE, warning=FALSE}
plot_pred_comp1("Tottenham", "Chelsea", matrix_samples1)
```

Aquí descubrimos que sin importar que cambiemos de lugar a los equipos, los datos simulados muestran que el `Chelsea` gana por mímino, salvo que ahora es equipo visitante, y los datos históricos muestran igualmente que el `Chelsea` gana aún cuando es equipo visitante.

Derivado de la diferencia mínima que observamos en nuestro modelo, consideramos que predice con la precisión requerida, ya que no considera la ventaja de ser el equipo local. Esto da lugar a la segunda etapa del modelo.

## Iteración 2

Para tener en cuenta la ventaja de jugar en casa, cambiaremos nuestro modelo inicial donde dividiremos la línea base (baseline) en dos componentes: 1. Una línea base (home_baseline) local 2. Una línea base (away_baseline) visitante. El siguiente modelo `JAGS` aplica el cambio mencionado anteriormente:

```{r  model2, echo=FALSE, tidy=FALSE}
model2<- "model {
for(i in 1:n_games) {
  HomeGoals[i] ~ dpois(lambda_home[HomeTeam[i],AwayTeam[i]])
  AwayGoals[i] ~ dpois(lambda_away[HomeTeam[i],AwayTeam[i]])
}

for(home_i in 1:n_teams) {
  for(away_i in 1:n_teams) {
    lambda_home[home_i, away_i] <- exp( home_baseline + skill[home_i] - skill[away_i])
    lambda_away[home_i, away_i] <- exp( away_baseline + skill[away_i] - skill[home_i])
  }
}

skill[1] <- 0 
for(j in 2:n_teams) {
  skill[j] ~ dnorm(group_skill, group_tau)
}

group_skill ~ dnorm(0, 0.0625)
group_tau <- 1/pow(group_sigma, 2)
group_sigma ~ dunif(0, 3)

home_baseline ~ dnorm(0, 0.0625)
away_baseline ~ dnorm(0, 0.0625)
}"
```

```{r fit_model2, warning=FALSE, message=FALSE, echo=FALSE, results='hide', cache=TRUE}
model2_fit <- jags.model(textConnection(model2), data=data_list, 
                         n.chains=4, n.adapt=5000)
update(model2_fit, 5000)
samples2 <- coda.samples(model2_fit, 
                         variable.names=c("home_baseline", "away_baseline","skill", "group_sigma", "group_skill"),
                         n.iter=10000, thin=2)
matrix_samples2 <- as.matrix(samples2)
```

```{r tbl_model2, echo=FALSE}
sum_samples2 <- summary(samples2)
summary_df2 <- as.data.frame(sum_samples2$statistics)
summary_df2$parameter <- rownames(summary_df2)

quantiles_df2 <- as.data.frame(sum_samples2$quantiles)
quantiles_df2$parameter <- rownames(quantiles_df2)
summary_combined_df2 <- left_join(summary_df2, quantiles_df2, 
                                  by = "parameter")

tbl_model2 <- summary_combined_df2 |>
  select(parameter, Mean, SD = SD, "2.5%", "97.5%")

tbl_model2 |>
  gt() |>
  fmt_number(columns = c("Mean", "SD", "2.5%", "97.5%"), 
             decimals = 3)
```

Al revisar los gráficos de traza y distribución de los parámetros de linea base local (home_baseline) y linea base visitante (away_baseline), se observa la ventaja para el equipo que juega como local.

```{r graphs_model2_home_baseline, warning=FALSE, echo=FALSE}
mean_hbl <- tbl_model2$Mean[4]

mcmc_trace_hbl <- MCMCtrace(samples2, params = "home_baseline",
                           ISB = FALSE, 
                           exact = TRUE, 
                           pdf = FALSE,
                           ind = TRUE,
                           main_tr = 'Traza de Home Baseline',
                           main_den = 'Distribución de Home Baseline',
                           gvals = mean_hbl)
```

```{r graphs_model2_away_baseline, warning=FALSE, echo=FALSE}
mean_awl <- tbl_model2$Mean[1]

mcmc_trace_awl <- MCMCtrace(samples2, params = "away_baseline",
                           ISB = FALSE, 
                           exact = TRUE, 
                           pdf = FALSE,
                           ind = TRUE,
                           main_tr = 'Traza de Away Baseline',
                           main_den = 'Distribución de Away Baseline',
                           gvals = mean_awl)
```

Veamos la diferencia entre `exp(home_baseline)` y `exp(away_baseline)` para mostrar la ventaja que tiene el equipo como local en términos de número de goles esperados.

```{r graphs_model2_diff_baseline, warning=FALSE, echo=FALSE, results='hide'}
setwd("../Proyecto MLG")
plotPost(exp(matrix_samples2[,"home_baseline"]) - exp(matrix_samples2[,"away_baseline"]), compVal=0, 
        xlab="Home advantage in number of goals")
```

Por último, veremos los resultados simulados del `Chelsea` (HomeTeam) contra el `Tottenham` (AwayTeam) utilizando las estimaciones del nuevo modelo (model2), con la primera fila del gráfico mostrando el resultado previsto y la segunda mostrando los datos reales.

```{r match_result_TottenhamvsChelsea_model2, echo=FALSE, warning=FALSE}
plot_pred_comp2 <- function(home_team, away_team, ms) {
  home_baseline <- ms[, "home_baseline"]
  away_baseline <- ms[, "away_baseline"]
  home_skill <- ms[, col_name("skill", which(teams == home_team))]
  away_skill <- ms[, col_name("skill", which(teams == away_team))]
  
  home_goals_sim <- rpois(nrow(ms), 
                          exp(home_baseline + home_skill - away_skill))
  away_goals_sim <- rpois(nrow(ms), 
                          exp(away_baseline + away_skill - home_skill))
  
  sim_plots <- plot_goals(home_goals_sim, 
                          away_goals_sim, 
                          "(Simulated)")
  
  home_goals_real <- d$HomeGoals[d$HomeTeam == home_team & 
                                   d$AwayTeam == away_team]
  away_goals_real <- d$AwayGoals[d$HomeTeam == home_team & 
                                   d$AwayTeam == away_team]
  
  real_plots <- plot_goals(home_goals_real, 
                           away_goals_real, 
                           "(Actual)")
  
  grid.arrange(
    sim_plots[[1]], sim_plots[[2]], 
    sim_plots[[3]], sim_plots[[4]],
    real_plots[[1]], real_plots[[2]], 
    real_plots[[3]], real_plots[[4]],
    nrow = 2, ncol = 4
  )
}
```

```{r graphs_model2_ChelseavsTottenham, echo=FALSE, warning=FALSE}
plot_pred_comp2("Chelsea", "Tottenham", matrix_samples2)
```

Y similarmente, `Tottenham` (HomeTeam) contra el `Chelsea` (AwayTeam):

```{r graphs_model2_TottenhamvsChelsea, echo=FALSE, warning=FALSE}
plot_pred_comp2("Tottenham", "Chelsea", matrix_samples2)
```

Ahora los resultados se acercan más a los datos históricos, ya que tanto el `Tottenham` como el `Chelsea` tienen más probabilidades de ganar cuando juegan como locales.

En este punto del proceso de modelado, decidimos ajustar la habilidad de los equipos en función de la temporada, ya que los equipos pueden cambiar su habilidad de un año a otro.

## Iteración 3

El modelo actual no tiene en cuenta la evolución de las habilidades de los equipos a lo largo del tiempo, ya que actualmente se supone que tiene la misma habilidad durante el periodo observado, probablemente esto no sea una suposición realista, ya que los equipos difieren en su rendimiento año tras año. Para tener en cuenta esto, se puede suponer que la habilidad de un equipo en una temporada esta en función de su habilidad en la temporada anterior. Y lo que es más, algunos equipos ni siquiera participan en todas las temporadas del conjunto de datos de la liga como muestra el siguiente diagrama:

```{r teams_participation, echo=FALSE}
ggplot(d, aes(x = Season, y = HomeTeam)) +
  geom_point() +
  labs(y = "Team", x = "Participation by Season") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

En la tercer iteración del modelo, se incluye la variabilidad interanual de la habilidad (skill) de los equipos. Esto se hizo permitiendo que cada equipo tuviera un parámetro de habilidad (skill) por temporada (season), pero conectando los parámetros de habilidad (skill), es decir, el parámetro de habilidad (skill) de un equipo para la temporada (season) $t$ en la distribución a priori para el parámetro de habilidad de ese equipo para la temporada $t + 1$, de modo que $$skill_{t+1} \sim Normal(skill_t, \sigma^2_{season})$$

para todas las diferentes $t$, excepto la primera temporada, que recibe una distribución a priori no informativa. En este caso, $\sigma^2_{season}$ es un parámetro estimado a partir de todo el conjunto de datos disponibles. Las líneas de base local (home_baseline) y visitante (away_baseline) reciben el mismo tipo de a priori y a continuación, se muestra el modelo `JAGS` resultante.

```{r model3, echo=FALSE, tidy=FALSE}
model3 <- "model {
for(i in 1:n_games) {
  HomeGoals[i] ~ dpois(lambda_home[Season[i], HomeTeam[i],AwayTeam[i]])
  AwayGoals[i] ~ dpois(lambda_away[Season[i], HomeTeam[i],AwayTeam[i]])
}

for(season_i in 1:n_seasons) {
  for(home_i in 1:n_teams) {
    for(away_i in 1:n_teams) {
      lambda_home[season_i, home_i, away_i] <- exp( home_baseline[season_i] + skill[season_i, home_i] - skill[season_i, away_i])
      lambda_away[season_i, home_i, away_i] <- exp( away_baseline[season_i] + skill[season_i, away_i] - skill[season_i, home_i])
    }
  }
}

skill[1, 1] <- 0 
for(j in 2:n_teams) {
  skill[1, j] ~ dnorm(group_skill, group_tau)
}

group_skill ~ dnorm(0, 0.0625)
group_tau <- 1/pow(group_sigma, 2)
group_sigma ~ dunif(0, 3)

home_baseline[1] ~ dnorm(0, 0.0625)
away_baseline[1] ~ dnorm(0, 0.0625)

for(season_i in 2:n_seasons) {
  skill[season_i, 1] <- 0 
  for(j in 2:n_teams) {
    skill[season_i, j] ~ dnorm(skill[season_i - 1, j], season_tau)
  }
  home_baseline[season_i] ~ dnorm(home_baseline[season_i - 1], season_tau)
  away_baseline[season_i] ~ dnorm(away_baseline[season_i - 1], season_tau)
}

season_tau <- 1/pow(season_sigma, 2) 
season_sigma ~ dunif(0, 3) 
}"
```

Desafortunadamente, estos cambios en el modelo introdujeron autocorrelación al ejecutar el muestreador MCMC, por lo que se optó por aumentar el número de muestras y la cantidad de adelgazamiento.

```{r fit_model3, warning=FALSE, message=FALSE, echo=FALSE, results='hide', cache=TRUE}
model3_fit <- jags.model(textConnection(model3), data=data_list, 
                         n.chains=3, n.adapt=10000)
update(model3_fit, 10000)
samples3 <- coda.samples(model3_fit, 
                         variable.names=c("home_baseline", 
                                          "away_baseline",
                                          "skill", 
                                          "season_sigma", 
                                          "group_sigma", 
                                          "group_skill"),
                         n.iter=40000, thin=8)
matrix_samples3 <- as.matrix(samples3)
```

```{r tbl_model3, echo=FALSE}
sum_samples3 <- summary(samples3)
summary_df3 <- as.data.frame(sum_samples3$statistics)
summary_df3$parameter <- rownames(summary_df3)

quantiles_df3 <- as.data.frame(sum_samples3$quantiles)
quantiles_df3$parameter <- rownames(quantiles_df3)
summary_combined_df3 <- left_join(summary_df3, quantiles_df3, by = "parameter")

tbl_model3 <- summary_combined_df3 |>
  select(parameter, Mean, SD = SD, "2.5%", "97.5%")

tbl_model3 |>
  gt() |>
  fmt_number(columns = c("Mean", "SD", "2.5%", "97.5%"), decimals = 3)
```

Las siguientes gráficas muestran la traza y la distribución del parámetro "season sigma".

```{r graphs_model_skills, warning=FALSE, echo=FALSE}
mean_hbl <- tbl_model3$Mean[31]

mcmc_trace_ss <- MCMCtrace(samples3, params = "season_sigma",
                           ISB = FALSE, 
                           exact = TRUE, 
                           pdf = FALSE,
                           ind = TRUE,
                           main_tr = 'Traza de Season Sigma',
                           main_den = 'Distribución de Season Sigma',
                           gvals = mean_hbl)
```

Desde el punto de vista de la estadística bayesiana, utilizamos métricas como el LOO (Leave-One-Out Cross-Validation) y el WAIC (Widely Applicable Information Criterion) para evaluar y comparar la capacidad predictiva de los 3 modelos. Ambas métricas nos permiten estimar la calidad predictiva de un modelo penalizando su complejidad para evitar sobreajustes. A continuación, se mostrará el comparativo de los modelos mediante el uso de LOO y WAIC.

```{r compare_models, echo=FALSE, warning=FALSE, cache=TRUE}
dic_m1 <- dic.samples(model1_fit, 40000, "pD")
dic_m2 <- dic.samples(model2_fit, 40000, "pD")
dic_m3 <- dic.samples(model3_fit, 40000, "pD")
```

```{r echo=FALSE}
diffdic_m1_m2 <- diffdic(dic_m1, dic_m2)
diffdic_m2_m3 <- diffdic(dic_m2, dic_m3)

diff_m1_m2 <- diffdic_m1_m2[1]
se_m1_m2 <- diffdic_m1_m2[2]

diff_m2_m3 <- diffdic_m2_m3[1]
se_m2_m3 <- diffdic_m2_m3[2]


diff_dic_results <- data.frame(
  Comparison = c("Model 1 vs Model 2", "Model 2 vs Model 3"),
  Difference = c(diff_m1_m2, diff_m2_m3),
  Std_Error = c(se_m1_m2, se_m2_m3)
)

diff_dic_results %>%
  gt() %>%
  tab_header(
    title = md("**Comparación de Modelos usando DIC**"),
    subtitle = md("Diferencias de DIC y su interpretación")
  ) %>%
  fmt_number(columns = c(Difference, Std_Error), decimals = 4)
```

**La Iteración 3** es el modelo más adecuado para futuros análisis y predicciones, ya que ofrece el mejor equilibrio entre capacidad predictiva y complejidad del modelo. Aunado a lo anterior, consideramos que los supuestos del modelo actual (model3) son más razonables, así que con base en los resultados del comparativo y de los supuestos utilizados elegimos este modelo como el mejor. Ahora es el momento de completar los objetivos establecidos en la introducción. Es decir, clasificar a los equipos de Premier League y predecir el resultado de los partidos futuros.

# Clasificación de los equipos de la Premier League

Comenzaremos por clasificar a los equipos de la liga utilizando los parámetros de habilidad estimados de la temporada 2023/2024.Los valores de los parámetros de habilidad son difíciles de interpretar, ya que son relativos a la habilidad del equipo que tenía su parámetro de habilidad "anclado" en cero. Para ponerlos en una escala más interpretable, primero centraré a cero los parámetros de habilidad restando la habilidad media de todos los equipos, luego añadiré la línea de base local y exponenciaré los valores resultantes. Estos parámetros de habilidad reescalados están ahora en la escala del número esperado de goles cuando juega el equipo local. A continuación se muestra un gráfico de oruga de la mediana de los parámetros de habilidad reescalados junto con los intervalos de credibilidad del 68 % y el 95 %. El gráfico está ordenado según la mediana de la habilidad y, por tanto, también muestra la clasificación de los equipos.

```{r team_skills_samples, echo=FALSE}
team_skill <- matrix_samples3[, str_detect(string=colnames(matrix_samples3), "skill\\[5,")]
team_skill <- (team_skill - rowMeans(team_skill)) + 
  matrix_samples3[, "home_baseline[5]"]
team_skill <- exp(team_skill)
colnames(team_skill) <- teams
team_skill <- team_skill[,order(colMeans(team_skill), decreasing=T)]
old_par <- par(mar=c(2,0.7,0.7,0.7), xaxs='i')
caterplot(team_skill, labels.loc="above", val.lim=c(0.7, 3.8))
par(old_par)
```

```{r fig.height=3, fig.width=7, results='hide', echo=FALSE, warning=FALSE, message=FALSE}
plotPost(team_skill[, "Man City"] - team_skill[, "Liverpool"], compVal = 0, xlab = "← Liverpool     vs     Man City →")
```

El Man City es el mejor equipo con una probabilidad de `r round(mean(team_skill[, "Man City"] - team_skill[, "Liverpool"] > 0) * 100)` %.

# Predicción de los resultados de los partidos futuros

En el conjunto de datos de la Premier League faltan los resultados de los 23 últimos partidos de la temporada 2023/2024. Ya que la base cuenta con información al 6 de mayo de 2024, se utilizará el modelo para predecir los resultados de los partidos restantes.

Con el modelo podemos predecir y simular los resultados. El código R que se muestra a continuación calcula un número de medidas para cada partido (tanto los partidos con resultados conocidos como los desconocidos): - La moda del número simulado de goles, es decir, el número más probable de goles marcados. - La media del número simulado de goles, que es la mejor estimación del número medio de goles en un partido. - El resultado más probable para cada partido. - Una muestra aleatoria de las distribuciones de resultados creíbles de local, visitante y en los partidos.

```{r predict_results, tidy=FALSE, echo=FALSE}
n <- nrow(matrix_samples3)
m3_pred <- sapply(1:nrow(d), function(i) {
  home_team <- which(teams == d$HomeTeam[i])
  away_team <- which(teams == d$AwayTeam[i])
  season <- which(seasons == d$Season[i])
  home_skill <- matrix_samples3[, col_name("skill", season, home_team)] 
  away_skill <- matrix_samples3[, col_name("skill", season, away_team)]
  home_baseline <- matrix_samples3[, col_name("home_baseline", season)]
  away_baseline <- matrix_samples3[, col_name("away_baseline", season)]

  home_goals <- rpois(n, exp(home_baseline + home_skill - away_skill))
  away_goals <- rpois(n, exp(away_baseline + away_skill - home_skill))
  home_goals_table <- table(home_goals)
  away_goals_table <- table(away_goals)
  match_results <- sign(home_goals - away_goals)
  match_results_table <- table(match_results)
  
  mode_home_goal <- as.numeric(names(home_goals_table)[ which.max(home_goals_table)])
  mode_away_goal <- as.numeric(names(away_goals_table)[ which.max(away_goals_table)])
  match_result <-  as.numeric(names(match_results_table)[which.max(match_results_table)])
  rand_i <- sample(seq_along(home_goals), 1)
  
  c(mode_home_goal = mode_home_goal, mode_away_goal = mode_away_goal, match_result = match_result,
    mean_home_goal = mean(home_goals), mean_away_goal = mean(away_goals),
    rand_home_goal = home_goals[rand_i], rand_away_goal = away_goals[rand_i],
    rand_match_result = match_results[rand_i])
})
m3_pred <- t(m3_pred)
```

A continuación, se compara la distribución del número de goles en los datos con la moda, la media y el número aleatorio de goles previstos para todos los partidos (centrándonos en el número de goles del equipo local).\
En primer lugar, la distribución real del número de goles de los equipos locales.

```{r histogram_goals ,echo=FALSE, warning=FALSE}
ggplot(d, aes(x = HomeGoals)) +
  geom_histogram(breaks = (-1:10) + 0.5, color = "black", fill = "slateblue2", alpha = 0.7) +
  scale_x_continuous(limits = c(-0.5, 10), breaks = 0:10) +
  ggtitle("Histogram of Home Goals") +
  xlab("Home Goals") +
  ylab("Frequency")
```

Para casi todos los partidos el número más probable de goles es uno. En realidad, sin tener conocimiento alguno de fúbol, sería razonable apostar por un gol del equipo local, que es `r round(mean(m3_pred[ , "mode_home_goal"] == 1) * 100)`% de las veces la mejor apuesta. El siguiente gráfico muestra la distribución de los modas a partir de la distribución prevista de goles locales en cada partido. Es decir, cuál es el resultado más probable, para el equipo local, en cada partido.

```{r histogram_mode_home_goal ,echo=FALSE, warning=FALSE}
data <- data.frame(mode_home_goal = m3_pred[ , "mode_home_goal"])

ggplot(data, aes(x = mode_home_goal)) +
  geom_histogram(breaks = (-1:10) + 0.5, color = "black", fill = "turquoise3", alpha = 0.7) +
  scale_x_continuous(limits = c(-0.5, 10), breaks = 0:10) +
  ggtitle("Histogram of Mode Home Goal") +
  xlab("Mode Home Goal") +
  ylab("Frequency")

```

Para la mayoría de los partidos el número esperado de goles es 2. Es decir, incluso si tu apuesta más segura es un gol, esperarías ver alrededor de dos goles.

```{r histogram_mean_home_goal ,echo=FALSE, warning=FALSE}
data_mean <- data.frame(mean_home_goal = m3_pred[ , "mean_home_goal"])

ggplot(data_mean, aes(x = mean_home_goal)) +
  geom_histogram(breaks = (-1:10) + 0.5, color = "black", fill = "royalblue2", alpha = 0.7) +
  scale_x_continuous(limits = c(-0.5, 10), breaks = 0:10) +
  ggtitle("Histogram of Mean Home Goal") +
  xlab("Mean Home Goal") +
  ylab("Frequency")
```

La distribución de la moda y la media de goles no coincide con el número real de goles. Esto es inesperado, ya que se esperaría que la distribución de goles aleatorios (donde el número de goles para cada partido se ha extraído aleatoriamente de la distribución de goles en casa para ese partido) fuera similar al número real de goles en casa. Al observar el histograma a continuación, parece que esto es así.

```{r histogram_rand_home_goal ,echo=FALSE, warning=FALSE}
data_rand <- data.frame(rand_home_goal = m3_pred[ , "rand_home_goal"])

ggplot(data_rand, aes(x = rand_home_goal)) +
  geom_histogram(breaks = (-1:10) + 0.5, color = "black", fill = "salmon1", alpha = 0.7) +
  scale_x_continuous(limits = c(-0.5, 10), breaks = 0:10) +
  ggtitle("Histogram of Random Home Goal") +
  xlab("Random Home Goal") +
  ylab("Frequency")
```

También se evaluará la precisión del modelo en la predicción de los datos. Sin embargo, lo ideal sería usar la validación cruzada para esto, dado que el número de parámetros efectivos es considerablemente menor que la cantidad de puntos de datos, una comparación directa debería proporcionar una estimación razonable de la precisión de las predicciones.

```{r, echo=FALSE, warning=FALSE}
mode_pred <- mean(d$HomeGoals == m3_pred[, "mode_home_goal"], na.rm = TRUE)
mean_pred <- mean((d$HomeGoals - m3_pred[, "mean_home_goal"])^2, na.rm = TRUE)
 
results_table <- data.frame(
  Metric = c("Accuracy (Mode)", "Mean Squared Error (MSE)"),
  Value = c(mode_pred, mean_pred))
 
formatted_table <- results_table %>%
  gt() %>%
  tab_header(
    title = "Metricas del modelo de predicción de goles de Local"
  ) %>%
  fmt_number(
    columns = vars(Value),
    decimals = 3)
 
formatted_table
```

En promedio, el modelo predice correctamente el número de goles en casa el `r round(mean(laliga$HomeGoals == m3_pred[ , "mode_home_goal"], na.rm=T) * 100)`% de las veces y estima el número medio de goles con un error cuadrático medio de `r round(mean((laliga$HomeGoals - m3_pred[ , "mean_home_goal"])^2, na.rm=T), 2)`. A continuación, revisaremos los resultados reales y previstos de los partidos. El gráfico siguiente muestra los resultados de los partidos en los datos:

```{r histogram_games_results ,echo=FALSE, warning=FALSE}
data_gres <- data.frame(MatchResult = d$MatchResult)

ggplot(data_gres, aes(x = MatchResult)) +
  geom_histogram(breaks = (-2:1) + 0.5, color = "black", fill = "seagreen3", alpha = 0.7) +
  scale_x_continuous(breaks = -1:1, labels = c("Visitor Win", "Draw", "Home Win")) +
  ggtitle("Histogram of Match Results") +
  xlab("Match Result") +
  ylab("Frequency")
```

Para la mayoría de los partidos, la opción más segura es apostar por el equipo local. Aunque los empates ocurren con cierta frecuencia, nunca son la apuesta más confiable.

```{r histogram_match_result_pred ,echo=FALSE, warning=FALSE}
data_predmr <- data.frame(match_result_pred = m3_pred[ , "match_result"])

# Crear el gráfico de barras con ggplot2
ggplot(data_predmr, aes(x = match_result_pred)) +
  geom_bar(color = "black", fill = "seagreen3", alpha = 0.7) +
  scale_x_continuous(breaks = -1:1, labels = c("Visitor Win", "Draw", "Home Win")) +
  ggtitle("Histogram of Match Results") +
  xlab("Match Result") +
  ylab("Frequency")
```

Como en el caso del número de goles locales, los resultados aleatorios de los partidos tienen una distribución similar a los resultados reales de los partidos.

```{r histogram_rand_match_result ,echo=FALSE, warning=FALSE}
data_randmr <- data.frame(rand_match_result = m3_pred[ , "rand_match_result"])

ggplot(data_randmr, aes(x = rand_match_result)) +
  geom_bar(color = "black", fill = "seagreen3", alpha = 0.7) +
  scale_x_continuous(breaks = -1:1, labels = c("Visitor Win", "Draw", "Home Win")) +
  ggtitle("Histogram of Random Match Result") +
  xlab("Random Match Result") +
  ylab("Frequency")
```

El modelo predice el resultado correcto del partido el `r round(mean(d$MatchResult == m3_pred[ , "match_result"], na.rm=T) * 100)`% de las veces. Ahora que se ha comprobado que el modelo predice razonablemente la historia de la Premier League, se procederá a predecir el final de la liga. A continuación se presenta la predicción del número promedio de goles y la predicción del ganador para cada partido.

```{r results='asis'}
premier_forecast <- d[is.na(d$HomeGoals), c("Season", "HomeTeam", "AwayTeam")]
m3_forecast <- m3_pred[is.na(d$HomeGoals),] 
premier_forecast$mean_home_goals <- round(m3_forecast[,"mean_home_goal"], 1) 
premier_forecast$mean_away_goals <- round(m3_forecast[,"mean_away_goal"], 1)
premier_forecast$mode_home_goals <- m3_forecast[,"mode_home_goal"] 
premier_forecast$mode_away_goals <- m3_forecast[,"mode_away_goal"]
premier_forecast$predicted_winner <- ifelse(m3_forecast[ , "match_result"] == 1, premier_forecast$HomeTeam, 
                                           ifelse(m3_forecast[ , "match_result"] == -1, premier_forecast$AwayTeam, "Draw"))

rownames(premier_forecast) <- NULL
print(xtable(premier_forecast, align="ccccccccc"), type="html")
```

```{r}
library(knitr)
library(dplyr)

premier_forecast <- d[is.na(d$HomeGoals), c("Season", "Date", "HomeTeam", "AwayTeam")]
m3_forecast <- m3_pred[is.na(d$HomeGoals),] 
premier_forecast <- premier_forecast %>%
  mutate(
    mean_home_goals = round(m3_forecast[, "mean_home_goal"], 1),
    mean_away_goals = round(m3_forecast[, "mean_away_goal"], 1),
    mode_home_goals = m3_forecast[, "mode_home_goal"],
    mode_away_goals = m3_forecast[, "mode_away_goal"],
    predicted_winner = ifelse(m3_forecast[, "match_result"] == 1, HomeTeam, 
                              ifelse(m3_forecast[, "match_result"] == -1, AwayTeam, "Draw"))
  )

# Generar la tabla en formato Markdown
kable(premier_forecast, format = "markdown", align = "c")

```

# Resultados

La aplicación de los métodos a los datos. Los resultados deben ser presentados en forma fácil de entender, a través de gráficas, tablas de resumen de los resultados. En todos los casos, las gráficas y tablas tienen que ser relevantes para la comunicación de los resultados, no tienen que ser redundantes, y tienen que ser correctas.

\newpage

# Conclusiones

Un resumen de la conclusión del estudio, en donde se especifíque cómo se resolvió el problema propuesto, así como futuras vías de ampliación del estudio. También mencionar las limitaciones que se encontraron, y porqué no se pudieron atacar algunos aspectos originales del problema.

\newpage

# Fuentes

\newpage

# Anexos

## Anexo 1 - Funciones para simular partidos

```{r eval=FALSE}
# histogramas sobre los goles en casa, goles de visitante, 
# la diferencia de goles y un diagrama de barras sobre 
# los resultados del partido
plot_goals <- function(home_goals, away_goals) {
  n_matches <- length(home_goals)
  goal_diff <- home_goals - away_goals
  match_result <- ifelse(goal_diff < 0, 
                         "away_win", 
                         ifelse(goal_diff > 0, 
                                "home_win", 
                                "equal"))
  hist(home_goals, xlim=c(-0.5, 10), breaks=(0:100) - 0.5)
  hist(away_goals, xlim=c(-0.5, 10), breaks=(0:100) - 0.5)
  hist(goal_diff, xlim=c(-6, 6), breaks=(-100:100) - 0.5 )
  barplot(table(match_result) / n_matches , ylim=c(0, 1))
}

# Simula los marcadores de goles del juego utilizando 
# las muestras MCMC del modelo1
plot_pred_comp1 <- function(home_team, away_team, ms) {
  old_par <- par(mfrow = c(2, 4))
  baseline <- ms[, "baseline"]
  home_skill <- ms[, col_name("skill", which(teams == home_team))]
  away_skill <- ms[, col_name("skill", which(teams == away_team))]
  home_goals <- rpois(nrow(ms),  
                      exp(baseline +  home_skill - away_skill))
  away_goals <- rpois(nrow(ms),  
                      exp(baseline +  away_skill - home_skill))
  plot_goals(home_goals, away_goals)
  home_goals <- d$HomeGoals[ d$HomeTeam == home_team & 
                               d$AwayTeam == away_team]
  away_goals <- d$AwayGoals[ d$HomeTeam == home_team & 
                               d$AwayTeam == away_team]
  plot_goals(home_goals, away_goals)
  par(old_par)
}
```
